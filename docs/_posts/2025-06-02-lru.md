---
layout: post
title: "Under the Hood: Building a High-Performance LRU Cache for Our Actor-Based Key-Value Store"
date: 2025-06-02 00:41:00 +0400
categories: posts
---

<div class="post-content">
  <h2>Under the Hood: Building a High-Performance LRU Cache for Our Actor-Based Key-Value Store</h2>

  <p>In the world of high-performance systems, caching is king. For our open-source key-value store, a robust and efficient caching mechanism isn't just a feature, but a necessity. Today, I want to dive into the implementation of our <strong>Least Recently Used (LRU) cache</strong>, explore the design choices we made, and explain how it integrates seamlessly and safely with our actor-based architecture.</p>

  <h3>Why LRU?</h3>

  <p>The <strong>LRU cache eviction policy</strong> is a classic for a reason. It's simple, intuitive, and generally effective. When the cache reaches its capacity, the item that hasn't been accessed for the longest time is evicted, making space for new data. This policy assumes that data accessed recently is likely to be accessed again soon, which holds true for many real-world workloads.</p>

  <h3>Performance: O(1) for everything</h3>

   <p>Duva's LRU implementation combines a <code>HashMap</code> and a doubly linked list to provide <strong>O(1)</strong> performance for every operations:</p>
   <ul>
      <li><strong>1. GET </strong> </li>
      <li><strong>2. INSERT</strong> </li>
      <li><strong>3. REMOVE</strong> </li> 
      <li><strong>4. UPDATE</strong> </li>
   </ul>


  <h3>The <code>unsafe</code> Reality: Raw Pointers for Performance</h3>

  <p>One of the most notable aspects of the implementation is the judicious use of <code>unsafe</code> Rust. Specifically, we use raw pointers (<code>*mut CacheNode</code>) to enable three pointers pointing to the cache node.</p>

  <p>Why <code>unsafe</code>? In Rust, building a classic doubly linked list without <code>unsafe</code> is notoriously difficult due to strict ownership and borrowing rules. Each node needs mutable references to its neighbors, creating a cyclical reference problem that <code>Box</code> or <code>Rc&lt;RefCell&lt;...&gt;&gt;</code> can't solve efficiently.</p> - By inefficent, I mean it was around 50% slower in our benchmark and we decided against that option. 

  <p>Using raw pointer, we take manual yet rather brave control over memory and pointer management. This allows us to:</p>

  <ul>
    <li><strong>Avoid <code>Rc</code> Overhead:</strong> We eliminate the runtime cost of reference counting.</li>
    <li><strong>Prevent Runtime Borrow Check Panics:</strong> Unlike <code>RefCell</code>, raw pointers don't panic on aliasing — as long as we maintain our safety invariants.</li>
    <li><strong>Achieve True O(1) Performance:</strong> Linked list updates are extremely efficient via raw pointer manipulation.</li>
  </ul>

  <p><strong>A Note on Safety:</strong> Every <code>unsafe</code> block in our code is reviewed and documented. We maintain the invariant that all raw pointers refer to valid, allocated nodes currently managed by the LRU cache. But the real safety guard was not on this specific implementation but rather, the architecture we chose : actor model.</p>

  <h3>Safety in an Actor Model: The Game Changer</h3>

  <p>How do we reconcile <code>unsafe</code> internals with a safe user-facing API?</p>

  <p>We use the <strong>Actor Model</strong>. Each actor owns its own local shards with dedicated<code>LRUCache</code> and processes messages serially — ensuring there’s no concurrent access.</p>

  <p>This gives us:</p>

  <ul>
    <li><strong>Data Race Freedom:</strong> Only one thread touches a <code>LRUCache</code> at a time.</li>
    <li><strong>Safe Mutability:</strong> Actor boundaries enforce exclusive <code>&amp;mut self</code> access.</li>
  </ul>

  <p>Thus, even though we use <code>unsafe</code> internally, our system as a whole remains safe and race-free — the actor model acts as our concurrency guardian.</p>




  <h3>Conclusion</h3>

  <p>By embracing <code>unsafe</code> Rust and using raw pointers with care, we’ve built a high-performance LRU cache that offers <code>O(1)</code> access patterns. Thanks to our actor-based architecture, we ensure safety without compromising speed. This fusion of performance and correctness is key to a scalable, reliable key-value store.</p>

  <p>If you’re interested, dive into our codebase and join the project!</p>
</div>


<style>
  .post-content {
    max-width: 800px;
    margin: 0 auto;
    padding: 20px;
  }

  .post-content h2 {
    font-family: 'Quicksand', sans-serif;
    font-size: 1.8em;
    color: #ff5555;
    margin-top: 1.5em;
    border-bottom: 1px solid #e0e0e0;
    padding-bottom: 0.3em;
  }

  .post-content h3 {
    font-family: 'Quicksand', sans-serif;
    font-size: 1.4em;
    color: #333333;
    margin-top: 1.2em;
  }

  .post-content h4 {
    font-size: 1.2em;
    color: #666666;
    margin-top: 1em;
  }

  .post-content ul,
  .post-content ol {
    margin-left: 1.5em;
    line-height: 1.6;
  }

  .post-content li {
    margin-bottom: 0.5em;
  }

  .post-content p {
    margin-bottom: 1.2em;
    line-height: 1.6;
  }

  .command-example pre {
    background-color: #f5f5f5;
    border-left: 4px solid #ff5555;
    padding: 10px;
    overflow-x: auto;
    font-family: monospace;
    font-size: 0.95em;
    font-color: #4323;
  }
</style>